{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbey/miniconda3/envs/torch/lib/python3.12/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1708025845206/work/torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'BVP_function' from '/home/dbey/pinn-cm/inverse/BVP_function.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import BVP_function as bvp\n",
    "import numpy as np\n",
    "import deepxde as dde\n",
    "\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"whitegrid\") # better looking plots\n",
    "\n",
    "print(\"Using GPU:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "from importlib import reload\n",
    "reload(bvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbey/miniconda3/envs/torch/lib/python3.12/site-packages/skopt/space/space.py:111: UserWarning: Dimension (0.0, 1.0) was inferred to Real(low=0.0, high=1.0, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to <TypeError: Real.__init__() got an unexpected keyword argument 'tranform'>. See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "/home/dbey/miniconda3/envs/torch/lib/python3.12/site-packages/skopt/space/space.py:111: UserWarning: Dimension (0.0, 1.0) was inferred to Real(low=0.0, high=1.0, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to <TypeError: Real.__init__() got an unexpected keyword argument 'tranform'>. See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "/home/dbey/miniconda3/envs/torch/lib/python3.12/site-packages/skopt/space/space.py:111: UserWarning: Dimension (0.0, 1.0) was inferred to Real(low=0.0, high=1.0, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to <TypeError: Real.__init__() got an unexpected keyword argument 'tranform'>. See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "/home/dbey/miniconda3/envs/torch/lib/python3.12/site-packages/skopt/space/space.py:111: UserWarning: Dimension (0.0, 1.0) was inferred to Real(low=0.0, high=1.0, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to <TypeError: Real.__init__() got an unexpected keyword argument 'tranform'>. See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n",
      "/home/dbey/miniconda3/envs/torch/lib/python3.12/site-packages/skopt/space/space.py:111: UserWarning: Dimension (0.0, 1.0) was inferred to Real(low=0.0, high=1.0, prior='uniform', transform='identity'). In upcoming versions of scikit-optimize, it will be inferred to <TypeError: Real.__init__() got an unexpected keyword argument 'tranform'>. See the documentation of the check_dimension function for the upcoming API.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "reload(bvp)\n",
    "\n",
    "lmbd = 1.0\n",
    "lmbd_trainable = dde.Variable(lmbd - 0.2)\n",
    "mu = 0.5\n",
    "mu_trainable = dde.Variable(mu + 0.2)\n",
    "Q = 4.0\n",
    "\n",
    "domain = np.array([[0.0, 1.0], [0.0, 1.0]])\n",
    "geom = dde.geometry.Rectangle([0, 0], [1, 1])\n",
    "\n",
    "phy_params = {'lmbd': lmbd, 'mu': mu, 'Q': Q}\n",
    "phy_params_trainable = {'lmbd': lmbd_trainable, 'mu': mu_trainable, 'Q': Q}\n",
    "\n",
    "#net parameters\n",
    "net_type = ['Unet','USnet'][1]\n",
    "n_layers = 4\n",
    "size_layers = 50\n",
    "activation = ['tanh','ReLU','Sigmoid'][0]\n",
    "\n",
    "#loss parameters\n",
    "loss_type = ['pde','energy'][0] #the energy loss appears to crash LBFGS and provide less accurate results with Adam. PDE loss is therefore used in the following\n",
    "num_domain = 50**2\n",
    "train_distribution = ['uniform','pseudo','LHS','Halton','Hammersley','Sobol'][4]\n",
    "\n",
    "#boundary conditions\n",
    "bc_type = ['soft','hard'][1]\n",
    "num_boundary = 50\n",
    "\n",
    "#optimizer\n",
    "optimizers = [\"adam\",\"L-BFGS\"]\n",
    "learning_rates = [1e-3,None]\n",
    "iterations = [3000,None]\n",
    "\n",
    "config = {'net_type':net_type,'n_layers':n_layers,'size_layers':size_layers,'activation':activation,\n",
    "        'loss_type':loss_type,'num_domain':num_domain,'train_distribution':train_distribution,\n",
    "        'bc_type':bc_type,'num_boundary':num_boundary,\n",
    "        'optimizers':optimizers,'learning_rates':learning_rates,'iterations':iterations}  \n",
    "\n",
    "net_exact = bvp.set_exact_solution(net_type, phy_params,lib='torch')\n",
    "\n",
    "model, net_wrong_elasticity, pde_net, energy_net, mat_net = bvp.model_setup(geom, config, phy_params_trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_measures(domain, num_points, func, noise=0.0, seed=None):\n",
    "    X = np.linspace(domain[0][0], domain[0][1], int(np.sqrt(num_points)))\n",
    "    Y = np.linspace(domain[1][0], domain[1][1], int(np.sqrt(num_points)))\n",
    "    Xgrid, Ygrid = np.meshgrid(X, Y)\n",
    "    X_obs = np.hstack((Xgrid.reshape(-1, 1), Ygrid.reshape(-1, 1)))\n",
    "    Yexact = func(X_obs)\n",
    "    Y_obs = Yexact + noise * np.random.randn(*Yexact.shape)\n",
    "    return X_obs, Y_obs\n",
    "\n",
    "U_exact = lambda x: bvp.U_exact(x, params=phy_params)\n",
    "# generate training data\n",
    "X_obs, U_obs = generate_measures(domain, 400, U_exact, noise=0.0)\n",
    "\n",
    "observe_Ux = dde.PointSetBC(X_obs, U_obs[:, 0:1], component=0)\n",
    "observe_Uy = dde.PointSetBC(X_obs, U_obs[:, 1:2], component=1)\n",
    "\n",
    "geom = dde.geometry.Rectangle([0, 0], [1, 1])\n",
    "# material_behavior = dde.icbc.OperatorBC()\n",
    "bc = [observe_Ux, observe_Uy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.872422 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric   \n",
      "0         [2.22e+03, 2.66e+02, 2.16e+03]    [2.22e+03, 2.65e+02, 2.22e+03]    [1.14e+00]    \n",
      "1000      [9.23e+00, 2.75e+00, 6.79e+00]    [8.46e+00, 2.29e+00, 6.08e+00]    [5.85e-01]    \n",
      "2000      [8.18e-01, 4.60e-01, 1.24e+00]    [6.69e-01, 3.19e-01, 1.05e+00]    [5.77e-01]    \n",
      "3000      [2.01e-01, 1.44e-01, 3.48e-01]    [1.46e-01, 9.21e-02, 2.81e-01]    [5.82e-01]    \n",
      "4000      [8.40e-02, 5.86e-02, 1.36e-01]    [5.56e-02, 3.53e-02, 1.07e-01]    [5.88e-01]    \n",
      "5000      [3.51e-02, 2.60e-02, 5.94e-02]    [2.34e-02, 1.53e-02, 4.50e-02]    [5.94e-01]    \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 1.20e-01\n",
      "  test loss: 8.38e-02\n",
      "  test metric: [5.94e-01]\n",
      "\n",
      "'train' took 166.148171 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000844 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric   \n",
      "5000      [3.51e-02, 2.60e-02, 5.94e-02]    [2.34e-02, 1.53e-02, 4.50e-02]    [5.94e-01]    \n",
      "6000      [4.19e-03, 4.28e-03, 7.95e-03]    [2.87e-03, 3.07e-03, 5.43e-03]    [6.44e-01]    \n",
      "7000      [1.36e-03, 1.54e-03, 2.73e-03]    [9.89e-04, 1.14e-03, 1.73e-03]    [6.67e-01]    \n",
      "8000      [7.17e-04, 8.08e-04, 1.38e-03]    [5.44e-04, 6.15e-04, 8.28e-04]    [6.81e-01]    \n",
      "9000      [4.67e-04, 5.12e-04, 8.39e-04]    [3.65e-04, 3.95e-04, 4.84e-04]    [6.90e-01]    \n",
      "10000     [3.36e-04, 3.58e-04, 5.60e-04]    [2.69e-04, 2.78e-04, 3.15e-04]    [6.97e-01]    \n",
      "\n",
      "Best model at step 10000:\n",
      "  train loss: 1.25e-03\n",
      "  test loss: 8.61e-04\n",
      "  test metric: [6.97e-01]\n",
      "\n",
      "'train' took 165.440425 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000718 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric   \n",
      "10000     [3.36e-04, 3.58e-04, 5.60e-04]    [2.69e-04, 2.78e-04, 3.15e-04]    [6.97e-01]    \n",
      "11000     [2.86e-04, 3.05e-04, 4.35e-04]    [2.27e-04, 2.39e-04, 2.44e-04]    [7.00e-01]    \n",
      "12000     [2.30e-04, 2.46e-04, 3.28e-04]    [1.83e-04, 1.94e-04, 1.81e-04]    [7.03e-01]    \n",
      "13000     [1.86e-04, 1.97e-04, 2.50e-04]    [1.49e-04, 1.57e-04, 1.37e-04]    [7.07e-01]    \n",
      "14000     [1.55e-04, 1.62e-04, 1.96e-04]    [1.25e-04, 1.29e-04, 1.07e-04]    [7.10e-01]    \n",
      "15000     [1.32e-04, 1.36e-04, 1.60e-04]    [1.06e-04, 1.09e-04, 8.73e-05]    [7.13e-01]    \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 4.27e-04\n",
      "  test loss: 3.02e-04\n",
      "  test metric: [7.13e-01]\n",
      "\n",
      "'train' took 160.225159 s\n",
      "\n",
      "lambda:0.2157769501209259 ; mu: 0.2157769501209259\n"
     ]
    }
   ],
   "source": [
    "trainable_variables = [lmbd_trainable, mu_trainable]\n",
    "variable = dde.callbacks.VariableValue(trainable_variables, period=100, filename=\"elasticity_param.dat\")\n",
    "\n",
    "model.compile(\"adam\", lr=0.001, external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=5000,display_every=1000, callbacks=[variable])\n",
    "\n",
    "model.compile(\"adam\", lr=0.0001, external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=5000,display_every=1000, callbacks=[variable])\n",
    "\n",
    "model.compile(\"adam\", lr=0.0001, external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=5000,display_every=1000, callbacks=[variable])\n",
    "\n",
    "# # train lbfgs\n",
    "# model.compile(\"L-BFGS\", external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "# losshistory, train_state = model.train(callbacks=[variable])\n",
    "print(f\"lambda:{lmbd_trainable} ; mu: {mu_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
