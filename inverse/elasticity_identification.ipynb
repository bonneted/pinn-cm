{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'BVP_function' from 'C:\\\\Users\\\\u0150568\\\\PhD\\\\code\\\\github\\\\pinn-cm\\\\inverse\\\\BVP_function.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import BVP_function as bvp\n",
    "import numpy as np\n",
    "import deepxde as dde\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\") # better looking plots\n",
    "\n",
    "print(\"Using GPU:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "from importlib import reload\n",
    "reload(bvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(bvp)\n",
    "\n",
    "lmbd = 1.0\n",
    "lmbd_trainable = dde.Variable(lmbd - 0.2)\n",
    "mu = 0.5\n",
    "mu_trainable = dde.Variable(mu + 0.2)\n",
    "Q = 4.0\n",
    "\n",
    "domain = np.array([[0.0, 1.0], [0.0, 1.0]])\n",
    "geom = dde.geometry.Rectangle([0, 0], [1, 1])\n",
    "\n",
    "phy_params = {'lmbd': lmbd, 'mu': mu, 'Q': Q}\n",
    "phy_params_trainable = {'lmbd': lmbd_trainable, 'mu': mu_trainable, 'Q': Q}\n",
    "\n",
    "#net parameters\n",
    "net_type = ['Unet','USnet'][1]\n",
    "n_layers = 4\n",
    "size_layers = 50\n",
    "activation = ['tanh','ReLU','Sigmoid'][0]\n",
    "\n",
    "#loss parameters\n",
    "loss_type = ['pde','energy'][0] #the energy loss appears to crash LBFGS and provide less accurate results with Adam. PDE loss is therefore used in the following\n",
    "num_domain = 50**2\n",
    "train_distribution = ['uniform','pseudo','LHS','Halton','Hammersley','Sobol'][4]\n",
    "\n",
    "#boundary conditions\n",
    "bc_type = ['soft','hard'][1]\n",
    "num_boundary = 50\n",
    "\n",
    "#optimizer\n",
    "optimizers = [\"adam\",\"L-BFGS\"]\n",
    "learning_rates = [1e-3,None]\n",
    "iterations = [3000,None]\n",
    "\n",
    "config = {'net_type':net_type,'n_layers':n_layers,'size_layers':size_layers,'activation':activation,\n",
    "        'loss_type':loss_type,'num_domain':num_domain,'train_distribution':train_distribution,\n",
    "        'bc_type':bc_type,'num_boundary':num_boundary,\n",
    "        'optimizers':optimizers,'learning_rates':learning_rates,'iterations':iterations}  \n",
    "\n",
    "net_exact = bvp.set_exact_solution(net_type, phy_params,lib='torch')\n",
    "\n",
    "model, net_wrong_elasticity, pde_net, energy_net, mat_net = bvp.model_setup(geom, config, phy_params_trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_measures(domain, num_points, func, noise=0.0, seed=None):\n",
    "    X = np.linspace(domain[0][0], domain[0][1], int(np.sqrt(num_points)))\n",
    "    Y = np.linspace(domain[1][0], domain[1][1], int(np.sqrt(num_points)))\n",
    "    Xgrid, Ygrid = np.meshgrid(X, Y)\n",
    "    X_obs = np.hstack((Xgrid.reshape(-1, 1), Ygrid.reshape(-1, 1)))\n",
    "    Yexact = func(X_obs)\n",
    "    Y_obs = Yexact + noise * np.random.randn(*Yexact.shape)\n",
    "    return X_obs, Y_obs\n",
    "\n",
    "# generate training data\n",
    "X_obs, U_obs = generate_measures(domain, 400, U_exact, noise=0.0)\n",
    "\n",
    "observe_Ux = dde.PointSetBC(X_obs, U_obs[:, 0:1], component=0)\n",
    "observe_Uy = dde.PointSetBC(X_obs, U_obs[:, 1:2], component=1)\n",
    "\n",
    "geom = dde.geometry.Rectangle([0, 0], [1, 1])\n",
    "# material_behavior = dde.icbc.OperatorBC()\n",
    "bc = [observe_Ux, observe_Uy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.000313 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric   \n",
      "0         [2.23e+03, 2.67e+02, 2.23e+03]    [2.23e+03, 2.66e+02, 2.29e+03]    [1.14e+00]    \n",
      "1000      [1.11e+01, 3.13e+00, 6.34e+00]    [1.00e+01, 2.73e+00, 5.66e+00]    [5.91e-01]    \n",
      "2000      [9.96e-01, 5.10e-01, 1.27e+00]    [8.25e-01, 3.65e-01, 1.09e+00]    [5.91e-01]    \n",
      "3000      [2.69e-01, 1.48e-01, 4.08e-01]    [1.97e-01, 1.01e-01, 3.32e-01]    [5.99e-01]    \n",
      "4000      [9.64e-02, 5.19e-02, 1.54e-01]    [6.17e-02, 3.42e-02, 1.20e-01]    [6.06e-01]    \n",
      "5000      [4.12e-02, 2.44e-02, 7.16e-02]    [2.56e-02, 1.56e-02, 5.41e-02]    [6.13e-01]    \n",
      "\n",
      "Best model at step 5000:\n",
      "  train loss: 1.37e-01\n",
      "  test loss: 9.53e-02\n",
      "  test metric: [6.13e-01]\n",
      "\n",
      "'train' took 276.173838 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.000966 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric   \n",
      "5000      [4.12e-02, 2.44e-02, 7.16e-02]    [2.56e-02, 1.56e-02, 5.41e-02]    [6.13e-01]    \n",
      "6000      [4.81e-03, 3.92e-03, 8.01e-03]    [3.44e-03, 2.66e-03, 5.69e-03]    [6.60e-01]    \n",
      "7000      [1.16e-03, 1.02e-03, 1.86e-03]    [9.11e-04, 7.84e-04, 1.24e-03]    [6.84e-01]    \n",
      "8000      [6.26e-04, 5.13e-04, 8.24e-04]    [5.23e-04, 4.08e-04, 5.24e-04]    [6.97e-01]    \n",
      "9000      [3.85e-04, 3.16e-04, 4.76e-04]    [3.22e-04, 2.54e-04, 2.95e-04]    [7.06e-01]    \n",
      "10000     [2.81e-04, 2.29e-04, 3.16e-04]    [2.38e-04, 1.89e-04, 1.93e-04]    [7.12e-01]    \n",
      "\n",
      "Best model at step 10000:\n",
      "  train loss: 8.26e-04\n",
      "  test loss: 6.20e-04\n",
      "  test metric: [7.12e-01]\n",
      "\n",
      "'train' took 276.433328 s\n",
      "\n",
      "Compiling model...\n",
      "'compile' took 0.001206 s\n",
      "\n",
      "Training model...\n",
      "\n",
      "Step      Train loss                        Test loss                         Test metric   \n",
      "10000     [2.81e-04, 2.29e-04, 3.16e-04]    [2.38e-04, 1.89e-04, 1.93e-04]    [7.12e-01]    \n",
      "11000     [2.36e-04, 1.87e-04, 2.28e-04]    [2.02e-04, 1.54e-04, 1.38e-04]    [7.15e-01]    \n",
      "12000     [1.92e-04, 1.52e-04, 1.71e-04]    [1.65e-04, 1.26e-04, 1.02e-04]    [7.19e-01]    \n",
      "13000     [1.58e-04, 1.23e-04, 1.34e-04]    [1.36e-04, 1.03e-04, 7.91e-05]    [7.22e-01]    \n",
      "14000     [1.77e-04, 1.09e-04, 1.09e-04]    [1.62e-04, 9.29e-05, 6.41e-05]    [7.25e-01]    \n",
      "15000     [1.12e-04, 8.55e-05, 9.08e-05]    [9.57e-05, 7.23e-05, 5.37e-05]    [7.28e-01]    \n",
      "\n",
      "Best model at step 15000:\n",
      "  train loss: 2.88e-04\n",
      "  test loss: 2.22e-04\n",
      "  test metric: [7.28e-01]\n",
      "\n",
      "'train' took 276.330505 s\n",
      "\n",
      "lambda:0.2230997085571289 ; mu: 0.2230997085571289\n"
     ]
    }
   ],
   "source": [
    "trainable_variables = [lmbd_trainable, mu_trainable]\n",
    "variable = dde.callbacks.VariableValue(trainable_variables, period=100, filename=\"elasticity_param.dat\")\n",
    "\n",
    "model.compile(\"adam\", lr=0.001, external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=5000,display_every=1000, callbacks=[variable])\n",
    "\n",
    "model.compile(\"adam\", lr=0.0001, external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=5000,display_every=1000, callbacks=[variable])\n",
    "\n",
    "model.compile(\"adam\", lr=0.0001, external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "losshistory, train_state = model.train(iterations=5000,display_every=1000, callbacks=[variable])\n",
    "\n",
    "# # train lbfgs\n",
    "# model.compile(\"L-BFGS\", external_trainable_variables=trainable_variables, metrics=[\"l2 relative error\"])\n",
    "# losshistory, train_state = model.train(callbacks=[variable])\n",
    "print(f\"lambda:{lmbd_trainable} ; mu: {lmbd_trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-cuda",
   "language": "python",
   "name": "torch-cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
